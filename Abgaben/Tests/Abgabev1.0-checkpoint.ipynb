{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task A \n",
    "######  1 ) How many distances you need to calculate if you have 60,000 samples in the trainingset for 50 samples?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every picture has to check with every sample so through knn the algorithm calculates the distance of every v (v = samples = 50) to all samples in M (M = dataset / trainingset = 60.000).\n",
    "\n",
    "number of distances = M * v = 60.000 * 50 =  3.000.000 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2 ) How many distances do you need to calculate if you have n samples in the trainingset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of sample in the testset * the number of samples in the trainingset = total distance\n",
    "\n",
    "In this case: v * M = total distance\n",
    "              \n",
    "              50 * n = total distance \n",
    "              \n",
    "              50n = #total distances\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### What is the error rate of KNN on the test set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all needed classes\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data() \n",
    "# reshape the train samples into 2D arrays with images and digits \n",
    "x_train_flat = x_train.reshape([x_train.shape[0],x_train.shape[1] * x_train.shape[2]])\n",
    "x_test_flat = x_test.reshape([x_test.shape[0],x_test.shape[1] * x_test.shape[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the KNN models with k = 2,4,8\n",
    "k = 2\n",
    "# k = 4\n",
    "# k = 8\n",
    "knn_k = KNeighborsClassifier(n_neighbors=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=2, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit the model using x_train_flat as training data and y as y_train\n",
    "knn_k.fit(x_train_flat, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions on our test data\n",
    "knn_k_predictions = knn_k.predict(x_test_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score = f1_score(y_test, knn_k_predictions, average='micro') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'int' and 'function'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-a3c18d845512>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0merrorrate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'int' and 'function'"
     ]
    }
   ],
   "source": [
    "errorrate = 1 - f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:green\"> The global error rate is </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error rate 0.0373\n"
     ]
    }
   ],
   "source": [
    "#print('F1 Score:',f1_score)\n",
    "print('error rate',errorrate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### What is the error rate of KNN on the test set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 976    1    1    0    0    1    0    1    0    0]\n",
      " [   0 1133    2    0    0    0    0    0    0    0]\n",
      " [  11   10  995    1    2    0    0   12    1    0]\n",
      " [   1    1    8  981    1    9    0    6    2    1]\n",
      " [   3    7    0    0  959    0    2    3    0    8]\n",
      " [   6    2    0   25    2  850    2    1    1    3]\n",
      " [   7    3    0    0    5    4  939    0    0    0]\n",
      " [   0   29    8    2    3    0    0  981    0    5]\n",
      " [  10    2    8   28    9   29    4    5  876    3]\n",
      " [   6    6    3    9   19    4    1   22    2  937]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98       980\n",
      "           1       0.95      1.00      0.97      1135\n",
      "           2       0.97      0.96      0.97      1032\n",
      "           3       0.94      0.97      0.95      1010\n",
      "           4       0.96      0.98      0.97       982\n",
      "           5       0.95      0.95      0.95       892\n",
      "           6       0.99      0.98      0.99       958\n",
      "           7       0.95      0.95      0.95      1028\n",
      "           8       0.99      0.90      0.94       974\n",
      "           9       0.98      0.93      0.95      1009\n",
      "\n",
      "    accuracy                           0.96     10000\n",
      "   macro avg       0.96      0.96      0.96     10000\n",
      "weighted avg       0.96      0.96      0.96     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test, knn_k_predictions))\n",
    "print(classification_report(y_test, knn_k_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Additional information\n",
    "In this tasks, we decide to use the f1 score as the #1 metric for the error rate because it is the most important one and it combines precision and the recall results. To see the total number of all  true positives, false negatives and false positive we chose \"micro\" as the average parameter.\n",
    "Between these three models (k=2,4,8) the error rate do not differ that much. Here is a quick overview:\n",
    "\n",
    "\n",
    "1)\n",
    "\n",
    "\n",
    "2)\n",
    "\n",
    "\n",
    "3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###### How does the choice of k influence the results?\n",
    "In this case, changing the value of k does not have a huge influcen on the overall error rate. But if we go more detailed we can see that there is a diffrence between the individual error rates for each label (0-9). As shown in the table, with increasing label numbers, the error rate will increase too.This is because the more neighbors you consider for your decision, the more sceanrios are possible, and many of them are a very close call which - in some cases - might simply be wrong.\n",
    "But what is the right value for k? We tried it with this approach and get the best result:\n",
    "\n",
    "\n",
    "k = sqrt(n) // where n = number of data points in training data\n",
    "\n",
    "\n",
    "All in all, a small value of k means that noise will have a higher influence on the result and a large value make it computationally expensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
